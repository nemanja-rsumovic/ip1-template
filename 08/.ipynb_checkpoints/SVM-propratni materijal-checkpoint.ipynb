{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71fc7e89-eba2-4ae2-9e35-ee2b5c217148",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)\n",
    "\n",
    "## Uvod\n",
    "\n",
    "Support Vector Machine (SVM) je supervizirani algoritam za klasifikaciju i regresiju koji se često koristi u mašinskom učenju. Glavna ideja SVM-a je pronaći hiperravan koja najbolje razdvaja podatke različitih klasa. SVM je efikasan u visokodimenzionalnim prostorima i posebno dobar u situacijama s jasnom marginom separacije između klasa.\n",
    "\n",
    "## Osnovni princip\n",
    "\n",
    "### Linearna separacija\n",
    "\n",
    "Za početak, SVM traži linearnu separaciju podataka. Ako podaci nisu linearno separabilni u trenutnom prostoru, SVM može koristiti \"kernel trick\" za preslikavanje podataka u višedimenzionalni prostor gde su linearno separabilni.\n",
    "\n",
    "### Margina\n",
    "\n",
    "Margina je razmak između najbližih tačaka različitih klasa do razdvajajuće hiperravni. Cilj je maksimizirati ovu marginu, jer to dovodi do bolje generalizacije modela.\n",
    "\n",
    "### Lagranžovi multiplikatori\n",
    "\n",
    "Lagranžovi multiplikatori su ključni koncept u optimizaciji SVM-a. Oni se koriste za formiranje Lagranžove funkcije, koja omogućava rešavanje problema optimizacije sa ograničenjima. U SVM-u, Lagranžovi multiplikatori se koriste za formulisanje problema maksimizacije margine.\n",
    "\n",
    "#### Matematička formulacija\n",
    "\n",
    "Neka su $ x_i $ podaci, $ y_i $ njihove odgovarajuće klase, $ w $ težinski vektor, $ b $ bias, a $ \\xi_i $ su Lagranžovi multiplikatori koji odgovaraju ograničenjima naše optimizacione funkcije.\n",
    "\n",
    "Naša optimizaciona funkcija će biti:\n",
    "\n",
    "$$ \\text{minimize} \\left( \\frac{1}{2} \\|w\\|^2 + C \\sum_{i=1}^{n} \\xi_i \\right) $$\n",
    "\n",
    "gde su $ C $ parametar regularizacije, a $ \\sum_{i=1}^{n} \\xi_i $ penali za tačke koje su unutar margine ili su pogrešno klasifikovane.\n",
    "\n",
    "Ograničenja su:\n",
    "\n",
    "$$ y_i(w \\cdot x_i + b) \\geq 1 - \\xi_i $$\n",
    "$$ \\xi_i \\geq 0 $$\n",
    "\n",
    "### Izračunavanje margine\n",
    "\n",
    "#### 1. Udaljenost tačke od hiperravni\n",
    "\n",
    "Pretpostavimo da imamo tačku $ x_i $ na margini i normalu $ n $ na hiperravni. Udaljenost tačke $ x_i $ od hiperravni se može izračunati kao projekcija vektora $ x_i $ na normalu $ n $.\n",
    "\n",
    "Koristimo skalarni proizvod između vektora $ x_i $ i normala $ n $:\n",
    "\n",
    "$$ \\text{udaljenost} = \\frac{{|w \\cdot x_i + b|}}{{\\|w\\|}} $$\n",
    "\n",
    "Ovde, $ |w \\cdot x_i + b| $ je apsolutna vrednost skalarnog proizvoda između težinskog vektora $ w $ i tačke $ x_i $, dok je $ \\|w\\| $ norma težinskog vektora.\n",
    "\n",
    "#### 2. Izračunavanje širine margine\n",
    "\n",
    "Kako bismo odredili širinu margine, uzimamo u obzir udaljenosti do najbliže tačke različite klase. Budući da su tačke na margini klasifikovane tako da je $ w \\cdot x_i + b = \\pm 1 $, možemo koristiti tu činjenicu za izračunavanje udaljenosti do najbliže tačke na margini.\n",
    "\n",
    "Uzimamo najmanju udaljenost od tačke do hiperravni, što se može izraziti kao:\n",
    "\n",
    "$$ \\text{min\\_udaljenost} = \\min_{x_i \\in \\text{margina}} \\frac{{|w \\cdot x_i + b|}}{{\\|w\\|}} $$\n",
    "\n",
    "Širina margine se dobija udvostručenjem ove najmanje udaljenosti:\n",
    "\n",
    "$$ \\text{margina} = 2 \\cdot \\text{min\\_udaljenost} $$\n",
    "\n",
    "### Meka margina\n",
    "\n",
    "Do sada smo govorili o tzv. \"tvrdim\" SVM-om, gde smo pretpostavili da su podaci potpuno linearno separabilni i da nema grešaka u klasifikaciji. Međutim, u praksi, često se susrećemo s podacima koji nisu potpuno separabilni. Uvođenjem koncepta _meke margine_, omogućavamo SVM-u da toleriše neke greške u klasifikaciji i da pronađe ravnotežu između maksimizacije margine i minimizacije greške klasifikacije.\n",
    "\n",
    "Parametar $ C $ koji smo koristili u formulaciji optimizacione funkcije predstavlja penalizaciju za tačke unutar margine ili tačke koje su pogrešno klasifikovane. Veće vrednosti parametra $ C $ ukazuju na manju toleranciju grešaka, dok manje vrednosti parametra $ C $ omogućavaju veću toleranciju grešaka.\n",
    "\n",
    "Korišćenjem meke margine, SVM postaje fleksibilniji i može se prilagoditi realnim podacima koji često nisu potpuno separabilni.\n",
    "\n",
    "## Zaključak\n",
    "\n",
    "SVM je snažan algoritam za klasifikaciju i regresiju koji se često koristi u mašinskom učenju. Razumevanje osnovnih principa, uključujući detaljno izračunavanje margine i korišćenje Lagranžovih multiplikatora, ključno je za uspešnu primenu SVM-a u praksi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f9daf3-b19e-4e39-8367-cb969d83d4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
